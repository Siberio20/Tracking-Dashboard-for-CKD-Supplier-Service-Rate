{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasa de Servicio \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cáulculo de la Tasa de Servicio para los proveedores CKD para su cumplimiento en la Expedición (AVIEXP), el Embarque (ETD) y la Llegada a puerto (ETA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar Librerias que se van a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar Librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar Archivos de Trabajo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Archivos descargados desde SAP mediante la transacción VTT\n",
    "* Archivo con los datos de la VTT de cada sourcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Definir la ruta de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Define the path home\\npath=('C:/Users/Siberio/Desktop/Codigo TS/CSV/')\\nfile_list = os.listdir(path)\\n\\n#load the file with VTT info for each sourcing \\ndf_sourcings=pd.read_excel('C:/Users/Siberio/Desktop/Codigo TS/VTT FICHA.xlsx')\\n\""
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Define the path home\n",
    "path=('C:/Users/Siberio/Desktop/Codigo TS/CSV/')\n",
    "file_list = os.listdir(path)\n",
    "\n",
    "#load the file with VTT info for each sourcing \n",
    "df_sourcings=pd.read_excel('C:/Users/Siberio/Desktop/Codigo TS/VTT FICHA.xlsx')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the path\n",
    "path=('C:/Users/ax24491/Alliance/Aprovisionamiento Colombia - General/03. APPRO/02. CKD/Tasa de servicio/VTT Dashboard/Archivos VTT/CSV/')\n",
    "file_list = os.listdir(path)\n",
    "\n",
    "#load the file with VTT info for each sourcing \n",
    "df_sourcings=pd.read_excel('C:/Users/ax24491/Alliance/Aprovisionamiento Colombia - General/03. APPRO/02. CKD/Tasa de servicio/VTT Dashboard/VTT FICHA.xlsx')\n",
    "\n",
    "#df_cambios=pd.read_excel('C:/Users/ax24491/Alliance/Aprovisionamiento Colombia - General/03. APPRO/02. CKD/Tasa de servicio/VTT Dashboard/Cambios VTT.xlsx')\n",
    "\n",
    "#df_cambios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Combinar los archivos semanales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list for weekly files\n",
    "dataframes = [] # Create a empty list\n",
    "header_added = False  # To track if the header from the first file has been added\n",
    "\n",
    "#Add all file names to a list\n",
    "for file in file_list:\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(path, file)\n",
    "        df = pd.read_csv(file_path,sep=';',low_memory=False)\n",
    "    \n",
    "    #Add header of first file\n",
    "    if not header_added:\n",
    "        dataframes.append(df)  # Append the first DataFrame with header\n",
    "        header_added = True\n",
    "    else:\n",
    "        dataframes.append(df.iloc[1:])  # Append subsequent DataFrames without header\n",
    "\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "df_datos = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Filtrar la información, dejando solo las columnas necesarias y eliminando las filas repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Delete unused columns\n",
    "df_datos.drop(df_datos.columns[[0,1,3,6,7,8,9,10,11,12,13,14,15,16,17,18,20,21,22,23,24,25,26,27,30,31,33,34,35,36,37,38,39]],axis=1,inplace=True)\n",
    "df_datos.drop(df_datos.columns[7],axis=1,inplace=True)\n",
    "\n",
    "#Delete Suplementary RAN\n",
    "df_datos = df_datos[df_datos['SemRAN'].str.contains('S') == False]\n",
    "\n",
    "#Eliminar las Ran repetidas, conservando la que mas informacion contiene\n",
    "\n",
    "# Define a function to select the row with the least number of null values\n",
    "def select_row_least_nulls(group):\n",
    "    null_counts = group.isnull().sum(axis=1)\n",
    "    min_nulls = null_counts.min()\n",
    "    return group[null_counts == min_nulls].iloc[0]\n",
    "\n",
    "# Drop duplicates keeping the row with the least null values\n",
    "df_datos = df_datos.groupby('RAN', group_keys=False).apply(select_row_least_nulls).reset_index(drop=True)\n",
    "\n",
    "#Delete RAN´s without AVIEXP\n",
    "df_datos = df_datos.dropna(subset=['F.Real Exp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Unir la información de SAP con la información de la VTT, incluyendo posibles cambios que se hagan durante el año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ax24491\\AppData\\Local\\Temp\\ipykernel_12556\\3118095415.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cambios['Proveedor']=df_cambios['Proveedor'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "#Crear un df con las semanas a partir de las cuales aplican cambios a la VTT\n",
    "df_cambios=df_sourcings[['Proveedor','Semana Cambio']].copy\n",
    "\n",
    "\n",
    "df_cambios['Proveedor']=df_cambios['Proveedor'].astype(str)\n",
    "df_sourcings['Proveedor']=df_sourcings['Proveedor'].astype(str)\n",
    "df_sourcings['Semana Cambio']=df_sourcings['Semana Cambio'].astype(str)\n",
    "df_sourcings['Concat']=df_sourcings['Proveedor'].str.cat(df_sourcings['Semana Cambio'])\n",
    "\n",
    "df_datos['Proveedor']=df_datos['Proveedor'].astype(str)\n",
    "df_final=pd.merge(df_datos,df_cambios,on='Proveedor',how='inner')\n",
    "df_final['Semana Cambio']=df_final['Semana Cambio'].astype(int)\n",
    "df_final['Numero S.Ran']=df_final['SemRAN'].str[1:3].astype(int)\n",
    "\n",
    "\n",
    "def Calculate_VTT_to_apply(row):\n",
    "    Cambio=0\n",
    "    if int(row['Semana Cambio'])!=0:\n",
    "        if int(row['Numero S.Ran']) < int(row['Semana Cambio']):\n",
    "            Cambio=int(0)\n",
    "        else:\n",
    "            Cambio=row['Semana Cambio']\n",
    "    return Cambio\n",
    "\n",
    "df_final['Semana Cambio']=df_final.apply(Calculate_VTT_to_apply,axis=1)\n",
    "df_final.drop(['Numero S.Ran'],axis=1,inplace=True)\n",
    "\n",
    "df_final['Proveedor']=df_final['Proveedor'].astype(str)\n",
    "df_final['Semana Cambio']=df_final['Semana Cambio'].astype(str)\n",
    "df_final['Concat']=df_final['Proveedor'].str.cat(df_final['Semana Cambio'])\n",
    "df_final\n",
    "\n",
    "df_datos=pd.merge(df_final,df_sourcings,on='Concat',how='inner')\n",
    "df_datos.drop(['Semana Cambio_x','Concat','Semana Cambio_y','Proveedor_y'],axis=1,inplace=True)\n",
    "df_datos.rename(columns={'Proveedor_x':'Proveedor'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Reemplazar Valores para China (consolidación KWE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Material              object\n",
       "RAN                   object\n",
       "SemRAN                object\n",
       "Proveedor              int32\n",
       "F.Real Exp            object\n",
       "F.Real Emb            object\n",
       "ETA                   object\n",
       "Sourcing              object\n",
       "RAN INICIAL AVIEXP     int64\n",
       "RAN FINAL AVIEXP       int64\n",
       "RAN ETD                int64\n",
       "RAN INICIAL ETA        int64\n",
       "RAN FINAL ETA          int64\n",
       "DIA INICIAL EXP        int64\n",
       "DIA FINAL EXP          int64\n",
       "DIA ETD                int64\n",
       "DIA INICIAL ETA        int64\n",
       "DIA FINAL ETA          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Asignar codigo de proveedor 9999 para los sourcings que se consolidan en KWE\n",
    "dict_china={2063:9999,2165:9999,2212:9999,2953:9999,2999:9999,2201:9999,2164:9999,2157:9999,2266:9999,2273:9999}\n",
    "dict_china\n",
    "\n",
    "df_datos['Proveedor']=df_datos['Proveedor'].astype(int)\n",
    "df_datos['Proveedor'].replace(dict_china,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calcular la última semana del año anterior al año en curso, para tener en cuenta años de 52 y 53 semanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the last week of year-1\n",
    "def get_last_iso_week(year):\n",
    "    year=int(year)\n",
    "    last_day = datetime(year, 12, 31)\n",
    "    weekday = last_day.weekday()\n",
    "    days_to_subtract = (weekday - 3) % 7\n",
    "    last_iso_week_start = last_day - timedelta(days=days_to_subtract)\n",
    "    \n",
    "    # Calcula el número de la semana ISO\n",
    "    iso_week_number = last_iso_week_start.isocalendar()[1]\n",
    "    return iso_week_number\n",
    "\n",
    "current_year=datetime.now().year\n",
    "past_year=current_year-1\n",
    "last_iso_week_number = get_last_iso_week(past_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calcular semanas según parametros VTT para las 3 tasas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular semana real AVIEXP\n",
    "df_datos['F.Real Exp'] = pd.to_datetime(df_datos['F.Real Exp'], errors ='coerce',dayfirst=True)\n",
    "df_datos['F.Real Exp'].astype('int64').dtypes\n",
    "\n",
    "#Calcular semana real Embarque\n",
    "df_datos['F.Real Emb'] = pd.to_datetime(df_datos['F.Real Emb'], errors ='coerce',dayfirst=True)\n",
    "df_datos['F.Real Emb'].astype('int64').dtypes\n",
    "\n",
    "#Calcular semana real Puerto\n",
    "df_datos['ETA'] = pd.to_datetime(df_datos['ETA'], errors ='coerce',dayfirst=True)\n",
    "df_datos['ETA'].astype('int64').dtypes\n",
    "\n",
    "#Tomar solo el numero de la semana ran\n",
    "df_datos['Numero S.Ran']=df_datos['SemRAN'].str[1:3].astype(float)\n",
    "\n",
    "#Calculo Semana en la cual se va a considerar en el calculo de la Tasa\n",
    "df_datos['Semana Tasa AVIEXP']= df_datos['Numero S.Ran']-df_datos['RAN FINAL AVIEXP']\n",
    "df_datos['Semana Tasa ETD']=df_datos['Numero S.Ran']-df_datos['RAN ETD']\n",
    "df_datos['Semana Tasa ETA']=df_datos['Numero S.Ran']-df_datos['RAN FINAL ETA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calcular días según parametros VTT para las 3 tasas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para calcular una fecha ingresando el año, la semana y el día de la semana (1 lunes-7 domingo)\n",
    "def find_date_by_iso_week(year, iso_week, weekday):\n",
    "    if iso_week < 1 or iso_week > 53 or weekday < 1 or weekday > 7:\n",
    "        raise ValueError('El número de semana ISO debe estar entre 1 y 53, y el número de día de la semana debe estar entre 1 y 7.')\n",
    "    \n",
    "    date = datetime(year, 1, 1)\n",
    "    days_difference = weekday - date.isoweekday() % 7\n",
    "    if days_difference < 0:\n",
    "        days_difference += 7\n",
    "    \n",
    "    target_date = date + timedelta(days=days_difference + (iso_week - 1) * 7)\n",
    "    return target_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calcular Status AVIEXP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_Status_Aviexp(row):\n",
    "    year=datetime.now().year\n",
    "    sem_aviexp_estandar_i=row['Numero S.Ran']-row['RAN INICIAL AVIEXP']\n",
    "    sem_aviexp_estandar_f=row['Numero S.Ran']-row['RAN FINAL AVIEXP']\n",
    "\n",
    "#Calcular semana estandar en caso de que cambie de año\n",
    "    \n",
    "    if sem_aviexp_estandar_i<0:\n",
    "        year=year-1\n",
    "    if sem_aviexp_estandar_i <0:\n",
    "        sem_aviexp_estandar_i=last_iso_week_number-abs(sem_aviexp_estandar_i)\n",
    "    elif sem_aviexp_estandar_i ==0:\n",
    "        sem_aviexp_estandar_i=last_iso_week_number\n",
    "\n",
    "    if sem_aviexp_estandar_f <0:\n",
    "        sem_aviexp_estandar_f=last_iso_week_number-abs(sem_aviexp_estandar_f)\n",
    "    elif sem_aviexp_estandar_f ==0:\n",
    "        sem_aviexp_estandar_f=last_iso_week_number\n",
    "\n",
    "\n",
    "    target_date_i= find_date_by_iso_week(year, sem_aviexp_estandar_i, row['DIA INICIAL EXP']) #calcular fecha inicial AVIEXP segun VTT\n",
    "    target_date_f= find_date_by_iso_week(year, sem_aviexp_estandar_f, row['DIA FINAL EXP']) #calcular fecha final AVIEXP segun VTT\n",
    "\n",
    "\n",
    "    #Calcular status del Aviexp, en caso de que falten datos ejecuta la excepcion\n",
    "    try:\n",
    "        if row['F.Real Exp']>=target_date_i and row['F.Real Exp']<=target_date_f: \n",
    "            status_AVIEXP='A TIEMPO'  #Si la fecha de Aviexp está en el rango de la VTT\n",
    "        elif row['F.Real Exp']>target_date_f: \n",
    "            status_AVIEXP='EN ATRASO'  #Si la fecha de Aviexp es posterior al rango de la VTT\n",
    "        else:\n",
    "            status_AVIEXP='EN ADELANTO'  #Si la fecha de Aviexp es anteior al rango de la VTT\n",
    "    except:\n",
    "         status_AVIEXP='SIN DATOS'  #Si no hay datos para calcular\n",
    "\n",
    "    return status_AVIEXP\n",
    "\n",
    "#Crear columna Status AVIEXP y aplicar en cada fila la funcion de calculo del status        \n",
    "df_datos['Status AVIEXP']=df_datos.apply(Calculate_Status_Aviexp,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calcular Status Embarque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para calcular Status de Embarque\n",
    "def Calculate_Status_Embarque(row):\n",
    "    year=datetime.now().year\n",
    "    sem_embarque_estandar=row['Numero S.Ran']-row['RAN ETD']\n",
    "    \n",
    "\n",
    "#Calcular semana estandar en caso de que cambie de año\n",
    "    if sem_embarque_estandar<0:\n",
    "        year=year-1\n",
    "\n",
    "    if sem_embarque_estandar <0:\n",
    "        sem_embarque_estandar=last_iso_week_number-abs(sem_embarque_estandar)\n",
    "    elif sem_embarque_estandar ==0:\n",
    "        sem_embarque_estandar=last_iso_week_number\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    target_date= find_date_by_iso_week(year, sem_embarque_estandar, row['DIA ETD']) #calcular fecha ETD segun VTT\n",
    "\n",
    "\n",
    "    #Calcular status del Aviexp, en caso de que falten datos ejecuta la excepcion\n",
    "    try:\n",
    "        if row['F.Real Emb']==target_date: \n",
    "            status_Embarque='A TIEMPO'  #Si la fecha de Emabrque es igual a la VTT\n",
    "        elif row['F.Real Emb']>target_date: \n",
    "            status_Embarque='EN ATRASO'  #Si la fecha de Emabrque es posterior a la la VTT\n",
    "        else:\n",
    "            status_Embarque='EN ADELANTO'  #Si la fecha de Emabrque es anteior a la VTT\n",
    "    except:\n",
    "         status_Embarque='SIN DATOS'  #Si no hay datos para calcular\n",
    "\n",
    "    return status_Embarque\n",
    "\n",
    "\n",
    "#Crear columna Status ETD y aplicar en cada fila la funcion de calculo del status        \n",
    "df_datos['Status ETD']=df_datos.apply(Calculate_Status_Embarque,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Calcular Status Llegada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funcion para calcular Status de Llegada a Puerto\n",
    "def Calculate_Status_Llegada(row):\n",
    "    year=datetime.now().year\n",
    "    sem_ETA_estandar_i=row['Numero S.Ran']-row['RAN INICIAL ETA']\n",
    "    sem_ETA_estandar_f=row['Numero S.Ran']-row['RAN FINAL ETA']\n",
    "\n",
    "#Calcular semana estandar en caso de que cambie de año\n",
    "    \n",
    "    if sem_ETA_estandar_i<0:\n",
    "        year=year-1\n",
    "\n",
    "    if sem_ETA_estandar_i <0:\n",
    "        sem_ETA_estandar_i=last_iso_week_number-abs(sem_ETA_estandar_i)\n",
    "    elif sem_ETA_estandar_i ==0:\n",
    "        sem_ETA_estandar_i=last_iso_week_number\n",
    "\n",
    "    if sem_ETA_estandar_f <0:\n",
    "        sem_ETA_estandar_f=last_iso_week_number-abs(sem_ETA_estandar_f)\n",
    "    elif sem_ETA_estandar_f ==0:\n",
    "        sem_ETA_estandar_f=last_iso_week_number\n",
    "\n",
    "\n",
    "    target_date_i= find_date_by_iso_week(year, sem_ETA_estandar_i, row['DIA INICIAL ETA']) #calcular fecha inicial ETA segun VTT\n",
    "    target_date_f= find_date_by_iso_week(year, sem_ETA_estandar_f, row['DIA FINAL ETA']) #calcular fecha final ETA segun VTT\n",
    "\n",
    "\n",
    "    #Calcular status del ETA, en caso de que falten datos ejecuta la excepcion\n",
    "    try:\n",
    "        if row['ETA']>=target_date_i and row['ETA']<=target_date_f: \n",
    "            status_ETA='A TIEMPO'  #Si la fecha de ETA está en el rango de la VTT\n",
    "        elif row['ETA']>target_date_f: \n",
    "            status_ETA='EN ATRASO'  #Si la fecha de ETA es posterior al rango de la VTT\n",
    "        else:\n",
    "            status_ETA='EN ADELANTO'  #Si la fecha de ETA es anteior al rango de la VTT\n",
    "    except:\n",
    "         status_ETA='SIN DATOS'  #Si no hay datos para calcular\n",
    "\n",
    "    return status_ETA\n",
    "\n",
    "\n",
    "df_datos['Status ETA']=df_datos.apply(Calculate_Status_Llegada,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo Tasa de Servicio CKD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar filtros de sourcing y semanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasar df to numpy array\n",
    "\n",
    "sourcings = df_sourcings.to_numpy()\n",
    "final_file = df_datos.to_numpy()\n",
    "\n",
    "#definir variables\n",
    "sourcing_filter = []\n",
    "week_filter = []\n",
    "weeks = []\n",
    "negative_weeks = []\n",
    "status_filter = []\n",
    "suppliers = df_datos[\"Proveedor\"].unique()\n",
    "\n",
    "\n",
    "# Filter by sourcings\n",
    "def filter_sourcings():\n",
    "    for supplier in suppliers: \n",
    "        supplier_aux = []\n",
    "        for i in range(len(final_file)):\n",
    "            if final_file[i,3] == supplier:\n",
    "                supplier_aux.append(final_file[i])\n",
    "        sourcing_filter.append(supplier_aux)\n",
    "\n",
    "\n",
    "# Filter by sourcings and weeks. Columns 19, 20 and 21 are AVIEXP, ETD and ETA, respectively\n",
    "def filter_weeks(week):\n",
    "    for i in range(len(sourcing_filter)):\n",
    "        supplier = np.array(sourcing_filter[i])\n",
    "        min_week = np.min(supplier[:,week])\n",
    "        max_week = np.max(supplier[:,week])\n",
    "        if min_week == max_week:\n",
    "            number_of_weeks = np.arange(0, int(max_week)+1)\n",
    "        else: \n",
    "            number_of_weeks = np.arange(int(min_week), int(max_week)+1)\n",
    "        weeks.append(number_of_weeks)\n",
    "        weeks_by_sourcing = []\n",
    "        for j in range(len(number_of_weeks)):\n",
    "            weeks_aux = []\n",
    "            for k in range(len(supplier)):\n",
    "                if supplier[k,week] == number_of_weeks[j]:\n",
    "                    weeks_aux.append(supplier[k])\n",
    "            weeks_by_sourcing.append(weeks_aux)\n",
    "        week_filter.append(weeks_by_sourcing)\n",
    "\n",
    "\n",
    "# Filter by sourcings, weeks and status\n",
    "# Status are defined by AVIEXP, ETD and ETA. This columns are 22, 23 and 24\n",
    "\n",
    "def filter_by_status(week, status):\n",
    "    for i in range(len(week_filter)):\n",
    "        supplier = week_filter[i].copy()\n",
    "        status_filter_aux = []\n",
    "        for j in range(len(supplier)):\n",
    "            filter = supplier[j]\n",
    "            total = len(filter)\n",
    "            if total != 0:\n",
    "                in_advance = 0\n",
    "                on_time = 0\n",
    "                late = 0\n",
    "                for k in range(total):\n",
    "                    if filter[k][status] == \"EN ADELANTO\" and filter[k][week] > 0:\n",
    "                        in_advance += 1\n",
    "                    elif filter[k][status] == \"A TIEMPO\" and filter[k][week] > 0:\n",
    "                        on_time += 1\n",
    "                    elif filter[k][status] == \"EN ATRASO\" and filter[k][week] > 0:\n",
    "                        late += 1\n",
    "                ok = (in_advance + on_time)/total\n",
    "                nok = late/total\n",
    "            else:\n",
    "                ok = float('nan')\n",
    "            status_filter_aux.append(ok)\n",
    "        status_filter.append(status_filter_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar valores negativos para que no se considere en los cálculos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_weeks_method(status_array):\n",
    "    cont = 0\n",
    "    negative_weeks = []\n",
    "\n",
    "    for i in range(len(weeks)):\n",
    "        cont = 0\n",
    "        for j in range(len(weeks[i])):\n",
    "            if weeks[i][j] <= 0:\n",
    "                cont += 1\n",
    "        negative_weeks.append(cont)\n",
    "    \n",
    "    for i in range(len(status_array)):\n",
    "        if negative_weeks[i] != 0:\n",
    "            for j in range(negative_weeks[i]):\n",
    "                if negative_weeks[i] != 0:\n",
    "                    status_array[i][j] = float('nan')\n",
    "        start = weeks[i][0]\n",
    "        end = weeks[i][-1]\n",
    "        fee = status_array[i].copy()\n",
    "        for j in range(int(start)):\n",
    "            status_array[i][j] = float('nan')\n",
    "        for k in range(len(fee)):\n",
    "            if int(start) > len(status_array[i]):\n",
    "                status_array[i].append(fee[k])\n",
    "            else:\n",
    "                status_array[i][int(start)-1] = fee[k]\n",
    "            start += 1\n",
    "    return status_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weigthed_averages(sourcings_array, week, status):\n",
    "    weighted_averages_sourcing = []\n",
    "    for sourcing in sourcings_array:\n",
    "        if len(sourcing) != 0:\n",
    "            in_advance = 0\n",
    "            on_time = 0\n",
    "            for i in range(len(sourcing)):\n",
    "                if  sourcing[i][status] == \"EN ADELANTO\" and sourcing[i][week] > 0:\n",
    "                        in_advance += 1\n",
    "                elif sourcing[i][status] == \"A TIEMPO\" and sourcing[i][week] > 0:\n",
    "                        on_time += 1\n",
    "            ok = (in_advance + on_time)/len(sourcing)\n",
    "            weighted_averages_sourcing.append(ok)\n",
    "        else:\n",
    "             weighted_averages_sourcing.append(float('nan'))\n",
    "    return weighted_averages_sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcing_filter = []\n",
    "week_filter = []\n",
    "weeks = []\n",
    "negative_weeks = []\n",
    "status_filter = []\n",
    "filter_sourcings()\n",
    "status_name = [\"AVIEXP\", \"ETD\", \"ETA\"]\n",
    "weeks_number = [19, 20, 21]\n",
    "status_number = [22, 23, 24]\n",
    "suppliers_aux = suppliers.copy()\n",
    "suppliers_aux = np.insert(suppliers_aux,0,0)\n",
    "\n",
    "\n",
    "#Exortar archivos de las 3 tasas\n",
    "for i in range(len(status_name)):\n",
    "    week_filter = []\n",
    "    weeks = []\n",
    "    negative_weeks = []\n",
    "    status_filter = []\n",
    "    filter_weeks(weeks_number[i])\n",
    "    filter_by_status(weeks_number[i],status_number[i])\n",
    "    status_filter = negative_weeks_method(status_filter).copy()\n",
    "    status_filter.insert(0,np.arange(1,53))\n",
    "    weighted_average = weigthed_averages(sourcing_filter,weeks_number[i], status_number[i])\n",
    "    weighted_average.insert(0,0)\n",
    "    service_fee = pd.DataFrame(status_filter)\n",
    "    service_fee.insert(0, 'Proveedores', suppliers_aux)\n",
    "    service_fee.insert(1,'Promedio ponderado', weighted_average)\n",
    "    service_fee = service_fee.transpose()\n",
    "    #Exportar archivo\n",
    "    service_fee.to_csv(status_name[i] +'.csv', index = False, header = False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cambiar las semanas negativas por semanas del año anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Funcion para calcular la semana en caso de que cambie de año\\ndef calculate_past_year(row,column,last_iso_week_number):\\n    year=datetime.now().year\\n    if int(row[column]) < 0:\\n        year=year-1\\n\\n    if int(row[column]) <0:\\n        new_value=last_iso_week_number-abs(row[column])\\n    elif int(row[column]) ==0:\\n        new_value=last_iso_week_number\\n    else:\\n        new_value=row[column]\\n\\n    return int(new_value)\\n\\n\\n# Convertir los valores negativos a semanas del año anterior\\ndf_datos['Semana Tasa AVIEXP']=df_datos.apply(lambda row:calculate_past_year(row,'Semana Tasa AVIEXP',last_iso_week_number),axis=1)\\ndf_datos['Semana Tasa ETD']=df_datos.apply(lambda row:calculate_past_year(row,'Semana Tasa ETD',last_iso_week_number),axis=1)\\ndf_datos['Semana Tasa ETA']=df_datos.apply(lambda row:calculate_past_year(row,'Semana Tasa ETA',last_iso_week_number),axis=1)\\n\""
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Funcion para calcular la semana en caso de que cambie de año\n",
    "def calculate_past_year(row,column,last_iso_week_number):\n",
    "    year=datetime.now().year\n",
    "    if int(row[column]) < 0:\n",
    "        year=year-1\n",
    "\n",
    "    if int(row[column]) <0:\n",
    "        new_value=last_iso_week_number-abs(row[column])\n",
    "    elif int(row[column]) ==0:\n",
    "        new_value=last_iso_week_number\n",
    "    else:\n",
    "        new_value=row[column]\n",
    "\n",
    "    return int(new_value)\n",
    "\n",
    "\n",
    "# Convertir los valores negativos a semanas del año anterior\n",
    "df_datos['Semana Tasa AVIEXP']=df_datos.apply(lambda row:calculate_past_year(row,'Semana Tasa AVIEXP',last_iso_week_number),axis=1)\n",
    "df_datos['Semana Tasa ETD']=df_datos.apply(lambda row:calculate_past_year(row,'Semana Tasa ETD',last_iso_week_number),axis=1)\n",
    "df_datos['Semana Tasa ETA']=df_datos.apply(lambda row:calculate_past_year(row,'Semana Tasa ETA',last_iso_week_number),axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Exportar archivo consolidado cen formato csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#Exportar como csv el dataframe con toda la informacion\n",
    "#df_datos.to_csv('C:/Users/Siberio/Desktop/Codigo TS/Archivo_Final.csv',index=False,sep=';') #personal path\n",
    "df_datos.to_csv(r'C:\\Users\\ax24491\\Alliance\\Aprovisionamiento Colombia - General\\03. APPRO\\02. CKD\\Tasa de servicio\\VTT Dashboard\\Archivo_Final.csv',index=False,sep=';') #work path\n",
    "print(\"finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
